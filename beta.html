<!DOCTYPE html>
<html lang="en">
<head>
  <meta charset="UTF-8">
  <title>Advanced AI Chatbot – Optimized, Adaptive & Research-Driven</title>
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  <!-- Chart.js for live loss chart -->
  <script src="https://cdn.jsdelivr.net/npm/chart.js"></script>
  <!-- TensorFlow.js -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow/tfjs@latest"></script>
  <!-- Universal Sentence Encoder for natural language embeddings -->
  <script src="https://cdn.jsdelivr.net/npm/@tensorflow-models/universal-sentence-encoder"></script>
  <style>
    :root {
      --primary-bg: #1a1a1a;
      --secondary-bg: #2d2d2d;
      --accent: #4a90e2;
    }
    html, body {
      margin: 0;
      padding: 0;
      background: var(--primary-bg);
      color: #fff;
      font-family: 'Segoe UI', sans-serif;
      height: 100vh;
      display: flex;
      flex-direction: column;
    }
    /* Chat container */
    #chatContainer {
      flex: 1;
      overflow-y: auto;
      padding: 1rem;
      background: var(--secondary-bg);
      position: relative;
    }
    #chatLog {
      max-height: calc(100% - 2rem);
      overflow-y: auto;
    }
    #stepBar {
      padding: 0.5rem;
      text-align: center;
      background: var(--primary-bg);
      border-top: 1px solid #3d3d3d;
    }
    /* Input area */
    #inputContainer {
      display: flex;
      gap: 0.3rem;
      padding: 0.5rem;
      background: var(--primary-bg);
    }
    #userInput {
      flex: 1;
      padding: 0.4rem;
      font-size: 14px;
      border: 1px solid #3d3d3d;
      border-radius: 4px;
      background: var(--secondary-bg);
      color: #fff;
    }
    #sendButton {
      padding: 0.4rem 0.8rem;
      background: var(--accent);
      border: none;
      border-radius: 4px;
      cursor: pointer;
      font-size: 14px;
      transition: opacity 0.2s;
    }
    #sendButton:hover { opacity: 0.9; }
    /* Fixed panels */
    #controls, #infoPanel, #performancePanel {
      position: fixed;
      background: rgba(0,0,0,0.8);
      padding: 0.8rem;
      border-radius: 4px;
      font-size: 14px;
      z-index: 1000;
    }
    #controls {
      top: 1rem;
      right: 1rem;
      width: 360px;
      display: grid;
      grid-template-columns: 1fr 1fr;
      gap: 0.5rem;
    }
    #controls button.resetBtn {
      grid-column: span 2;
      background: #d9534f;
    }
    /* New innovation buttons */
    #controls button.extraBtn {
      grid-column: span 1;
      background: #5cb85c;
    }
    #infoPanel {
      top: 400px;
      right: 1rem;
      width: 320px;
    }
    #lossChartContainer {
      width: 100%;
      height: 200px;
    }
    #lossDisplay {
      margin-top: 0.5rem;
      text-align: center;
    }
    #dalleImage {
      width: 100%;
      margin-top: 1rem;
      border: 2px solid var(--accent);
    }
    #performancePanel {
      bottom: 1rem;
      right: 1rem;
      width: 320px;
    }
    .feedbackBtn {
      background: transparent;
      border: none;
      font-size: 14px;
      cursor: pointer;
      margin-left: 5px;
      color: var(--accent);
    }
  </style>
</head>
<body>
  <div id="chatContainer">
    <div id="chatLog"></div>
    <div id="stepBar">Steps: 0</div>
  </div>
  <div id="inputContainer">
    <input type="text" id="userInput" placeholder="Type your message here..." />
    <button id="sendButton">Send</button>
  </div>
  <div id="controls">
    <div style="grid-column: span 2;">
      <label>LR: <input type="number" id="lrInput" value="0.0005" step="0.0001"></label>
      <label>MutRate: <input type="number" id="mutRateInput" value="0.01" step="0.001"></label>
      <label>Decay: <input type="number" id="decayInput" value="0.999" step="0.001"></label>
      <label>Speed: <input type="range" id="speedInput" min="0.5" max="3" step="0.1" value="1"></label>
    </div>
    <button onclick="commander.trainExtra()">Train Extra</button>
    <button onclick="exportModel()">Export Model</button>
    <button onclick="document.getElementById('modelUpload').click()">Import Model</button>
    <button onclick="deepSeek()">Deep Seek</button>
    <button class="resetBtn" onclick="resetModel()">Reset Model</button>
    <!-- New innovation buttons -->
    <button class="extraBtn" onclick="showMemory()">Show Memory</button>
    <button class="extraBtn" onclick="saveChat()">Save Chat</button>
    <input type="file" id="modelUpload" style="display:none" accept=".json,.bin">
  </div>
  <div id="infoPanel">
    <div id="lossChartContainer">
      <canvas id="lossChart"></canvas>
    </div>
    <div id="lossDisplay">Loss: N/A</div>
    <!-- DALL·E image updated with AI art from Unsplash -->
    <img id="dalleImage" src="https://source.unsplash.com/320x200/?ai,art" alt="DALL-E Generated Image">
  </div>
  <div id="performancePanel"></div>

  <script>
    // Global conversation history and research-driven memory module.
    let conversationHistory = [];
    let useModel = null;
    // Global feedback counters.
    let totalFeedback = 0, positiveFeedback = 0, negativeFeedback = 0;

    // AdvancedMemoryModule stores conversation embeddings for retrieval.
    class AdvancedMemoryModule {
      constructor() {
        this.memories = [];
      }
      addMemory(embedding, text) {
        this.memories.push({embedding: embedding, text: text});
      }
      async searchMemory(query) {
        if (!useModel) return "";
        const queryEmb = await useModel.embed(query);
        const queryVec = (await queryEmb.array())[0];
        queryEmb.dispose();
        let bestSim = -Infinity, bestText = "";
        for (let mem of this.memories) {
          let sim = cosineSimilarity(queryVec, mem.embedding);
          if (sim > bestSim) { bestSim = sim; bestText = mem.text; }
        }
        return bestText;
      }
    }
    const memoryModule = new AdvancedMemoryModule();

    // PriorityReplayBuffer for prioritized experience replay.
    class PriorityReplayBuffer {
      constructor(maxSize) {
        this.buffer = [];
        this.maxSize = maxSize;
      }
      add(exp) {
        if (this.buffer.length >= this.maxSize) {
          this.buffer.shift();
        }
        this.buffer.push(exp);
      }
      sample(batchSize) {
        let priorities = this.buffer.map(e => Math.abs(e.reward) + 0.01);
        let total = priorities.reduce((a, b) => a + b, 0);
        let probs = priorities.map(p => p / total);
        let batch = [];
        for (let i = 0; i < batchSize; i++) {
          let rand = Math.random(), cumulative = 0;
          for (let j = 0; j < probs.length; j++) {
            cumulative += probs[j];
            if (rand < cumulative) { batch.push(this.buffer[j]); break; }
          }
        }
        return batch;
      }
      size() {
        return this.buffer.length;
      }
    }

    // Utility: cosine similarity between two vectors.
    function cosineSimilarity(vecA, vecB) {
      let dot = 0, normA = 0, normB = 0;
      for (let i = 0; i < vecA.length; i++) {
        dot += vecA[i] * vecB[i];
        normA += vecA[i] * vecA[i];
        normB += vecB[i] * vecB[i];
      }
      return dot / (Math.sqrt(normA) * Math.sqrt(normB) + 1e-8);
    }

    // Load Universal Sentence Encoder.
    (async function loadUSE() {
      try {
        useModel = await use.load();
        console.log("Universal Sentence Encoder loaded.");
      } catch (err) {
        console.error("Error loading USE:", err);
      }
    })();

    // Custom LambdaLayer for wrapping arbitrary functions.
    // (Now accepts an outputShape parameter so that tf.slice calls get proper shape info.)
    class LambdaLayer extends tf.layers.Layer {
      constructor(func, outputShape, config) {
        super(config || {});
        this.func = func;
        this._outputShape = outputShape;
      }
      call(inputs, kwargs) {
        return this.func(inputs);
      }
      computeOutputShape(inputShape) {
        if (this._outputShape) {
          if (typeof this._outputShape === 'function') {
            return this._outputShape(inputShape);
          }
          return this._outputShape;
        }
        return inputShape;
      }
      getClassName() {
        return 'LambdaLayer';
      }
    }

    (function(){
      // Set TensorFlow backend to WebGL and force lower precision textures.
      tf.setBackend('webgl');
      tf.env().set('WEBGL_FORCE_F16_TEXTURES', true);

      // Predefined responses from multiple APIs.
      const responses = [
        "Here's a joke: ",
        "Here's some advice: ",
        "Here's a quote: ",
        "Did you know? ",
        "Chuck Norris says: ",
        "Kanye says: "
      ];

      // --- API Fetch Functions ---
      async function safeFetch(url, options = {}) {
        try {
          const response = await fetch(url, options);
          if (!response.ok) throw new Error(`HTTP error! Status: ${response.status}`);
          return await response.text();
        } catch (error) {
          console.error("Fetch error:", error);
          try {
            const fallbackResponse = await fetch(url, { ...options, mode: "no-cors" });
            return await fallbackResponse.text();
          } catch (fallbackError) {
            console.error("Fallback fetch error:", fallbackError);
            return null;
          }
        }
      }
      async function fetchJoke() {
        const data = await safeFetch("https://icanhazdadjoke.com/", { headers: { "Accept": "text/plain" } });
        return data || "Sorry, no joke available.";
      }
      async function fetchAdvice() {
        const data = await safeFetch("https://api.adviceslip.com/advice");
        try { return data ? JSON.parse(data).slip.advice : "Sorry, no advice available."; }
        catch (e) { return "Sorry, no advice available."; }
      }
      async function fetchQuote() {
        const data = await safeFetch("https://api.quotable.io/random");
        try { return data ? JSON.parse(data).content : "Sorry, no quote available."; }
        catch (e) { return "Sorry, no quote available."; }
      }
      async function fetchCatFact() {
        const data = await safeFetch("https://catfact.ninja/fact");
        try { return data ? JSON.parse(data).fact : "Sorry, no cat fact available."; }
        catch (e) { return "Sorry, no cat fact available."; }
      }
      async function fetchChuckNorris() {
        try {
          const res = await safeFetch("https://api.chucknorris.io/jokes/random");
          if (res) {
            const data = JSON.parse(res);
            return data.value;
          }
          return "Sorry, no Chuck Norris joke available.";
        } catch (e) {
          console.error("Chuck Norris API error:", e);
          return "Error fetching Chuck Norris joke.";
        }
      }
      async function fetchKanye() {
        try {
          const res = await safeFetch("https://api.kanye.rest");
          if (res) {
            const data = JSON.parse(res);
            return data.quote;
          }
          return "Sorry, no Kanye quote available.";
        } catch (e) {
          console.error("Kanye API error:", e);
          return "Error fetching Kanye quote.";
        }
      }
      async function getResponse(action) {
        if (action === 0) {
          const joke = await fetchJoke();
          if (joke && !joke.startsWith("Error")) return responses[0] + joke;
          else return responses[1] + await fetchAdvice();
        } else if (action === 1) {
          const advice = await fetchAdvice();
          if (advice && !advice.startsWith("Error")) return responses[1] + advice;
          else return responses[0] + await fetchJoke();
        } else if (action === 2) {
          const quote = await fetchQuote();
          return responses[2] + quote;
        } else if (action === 3) {
          const catFact = await fetchCatFact();
          return responses[3] + catFact;
        } else if (action === 4) {
          const chuck = await fetchChuckNorris();
          return responses[4] + chuck;
        } else if (action === 5) {
          const kanye = await fetchKanye();
          return responses[5] + kanye;
        } else {
          return responses[action];
        }
      }

      // --- UI Helper Functions ---
      const chatLog = document.getElementById("chatLog");
      const stepBar = document.getElementById("stepBar");
      const userInput = document.getElementById("userInput");
      const sendButton = document.getElementById("sendButton");
      const performancePanel = document.getElementById("performancePanel");
      const lossDisplay = document.getElementById("lossDisplay");
      const lossChartCtx = document.getElementById("lossChart").getContext("2d");
      let lossChart = new Chart(lossChartCtx, {
        type: 'line',
        data: { labels: [], datasets: [{ label: 'Loss', data: [], borderColor: 'var(--accent)', fill: false }] },
        options: { responsive: true, maintainAspectRatio: false }
      });
      function appendMessage(sender, message, features = null) {
        const msgElem = document.createElement("div");
        msgElem.style.marginBottom = "10px";
        msgElem.innerHTML = `<strong>${sender}:</strong> ${message}`;
        // If the message is from Chatbot and includes feature info, add thumbs up/down buttons.
        if (sender === "Chatbot" && features) {
          const upBtn = document.createElement("button");
          upBtn.textContent = "👍";
          upBtn.classList.add("feedbackBtn");
          upBtn.addEventListener("click", (e) => {
            // Disable both buttons to prevent multiple feedback submissions.
            disableFeedbackButtons(e.target.parentElement);
            recordFeedback(e, features, true);
          });
          const downBtn = document.createElement("button");
          downBtn.textContent = "👎";
          downBtn.classList.add("feedbackBtn");
          downBtn.addEventListener("click", (e) => {
            disableFeedbackButtons(e.target.parentElement);
            recordFeedback(e, features, false);
          });
          msgElem.appendChild(upBtn);
          msgElem.appendChild(downBtn);
        }
        chatLog.appendChild(msgElem);
        chatLog.scrollTop = chatLog.scrollHeight;
      }
      // Disable any feedback buttons contained within the message element.
      function disableFeedbackButtons(parentElem) {
        const btns = parentElem.querySelectorAll("button.feedbackBtn");
        btns.forEach(btn => btn.disabled = true);
      }
      function argmax(arr) {
        let maxIndex = 0, maxValue = arr[0];
        for (let i = 1; i < arr.length; i++) {
          if (arr[i] > maxValue) { maxValue = arr[i]; maxIndex = i; }
        }
        return maxIndex;
      }
      function calculateReward(message, action) {
        const positiveKeywords = ["joke", "advice", "quote", "cat", "fascinating", "learn"];
        let reward = 0;
        for (let word of positiveKeywords) {
          if (message.toLowerCase().includes(word)) reward += 1;
        }
        if (action >= 2) reward += 0.5;
        return reward;
      }
      // Updated recordFeedback now receives the event so it can disable its buttons,
      // update global counters, and then trigger extra training.
      function recordFeedback(e, features, isPositive) {
        const feedbackReward = isPositive ? 5 : -5;
        commander.exp.push({ state: features, action: 0, reward: feedbackReward, nextState: features, done: false });
        commander.priorityBuffer.add({ state: features, action: 0, reward: feedbackReward, nextState: features, done: false });
        totalFeedback++;
        if (isPositive) {
          positiveFeedback++;
        } else {
          negativeFeedback++;
        }
        logEvent("Feedback recorded: " + (isPositive ? "👍" : "👎"));
        // Trigger additional training (as before).
        commander.trainExtra();
        // Update performance panel to reflect feedback statistics.
        updatePerformancePanel();
      }
      function updateStepDisplay(steps) {
        stepBar.textContent = "Steps: " + steps;
      }
      function updateLossChart(lossData) {
        lossChart.data.labels = lossData.map((v, i) => i);
        lossChart.data.datasets[0].data = lossData;
        lossChart.update();
      }
      function updatePerformancePanel() {
        performancePanel.innerHTML = `
          Steps: ${commander.stepCount} | Epsilon: ${commander.epsilon.toFixed(3)}<br>
          Feedback: ${positiveFeedback} 👍, ${negativeFeedback} 👎 (Total: ${totalFeedback})
        `;
      }
      function logEvent(msg) {
        console.log("[CHAT LOG]:", msg);
        let logs = localStorage.getItem("chatLogs");
        logs = logs ? JSON.parse(logs) : [];
        logs.push({ time: new Date().toISOString(), msg });
        localStorage.setItem("chatLogs", JSON.stringify(logs.slice(-100)));
      }

      // --- CommanderAgent with enhancements ---
      class CommanderAgent {
        constructor() {
          this.stepCount = 0;
          this.epsilon = 1.0;
          this.exp = []; // basic experience storage
          this.priorityBuffer = new PriorityReplayBuffer(512);
          this.learningRate = parseFloat(document.getElementById("lrInput").value);
          this.mutationRate = parseFloat(document.getElementById("mutRateInput").value);
          this.epsilonDecay = parseFloat(document.getElementById("decayInput").value);
          this.lossHistory = [];
          this.lossData = [];
          this.lossVarianceWindow = [];
          try {
            this.model = this.buildDuelingDQN();
            this.targetModel = this.buildDuelingDQN();
            this.targetModel.setWeights(this.model.getWeights());
          } catch (err) {
            console.error("Model construction error:", err);
            tf.env().set('WEBGL_FORCE_F16_TEXTURES', true);
            this.model = this.buildDuelingDQN();
            this.targetModel = this.buildDuelingDQN();
            this.targetModel.setWeights(this.model.getWeights());
          }
        }
        // Multi-head self-attention block.
        multiHeadSelfAttention(inputTensor, numHeads, dropoutRate = 0.1) {
          const tokenDim = inputTensor.shape[2];
          const depth = Math.floor(tokenDim / numHeads);
          const headOutputs = [];
          for (let i = 0; i < numHeads; i++) {
            const inputShape = inputTensor.shape; // expected [batch, tokens, tokenDim]
            const tokens = inputShape[1] || 8;
            const sliceOutputShape = [inputShape[0] || null, tokens, depth];
            const sliceLayer = new LambdaLayer(
              x => tf.slice(x, [0, 0, i * depth], [-1, -1, depth]),
              sliceOutputShape
            );
            const headInput = sliceLayer.apply(inputTensor);
            const Q = tf.layers.dense({ units: depth, useBias: false }).apply(headInput);
            const K = tf.layers.dense({ units: depth, useBias: false }).apply(headInput);
            const V = tf.layers.dense({ units: depth, useBias: false }).apply(headInput);
            const scores = tf.layers.dot({ axes: -1 }).apply([Q, K]);
            const divisor = tf.scalar(Math.sqrt(depth));
            const scaleLayer = new LambdaLayer(x => tf.div(x, divisor), null);
            const scaledScores = scaleLayer.apply(scores);
            const softmaxScores = tf.layers.activation({ activation: 'softmax' }).apply(scaledScores);
            const headOutput = tf.layers.dot({ axes: [2, 1] }).apply([softmaxScores, V]);
            headOutputs.push(headOutput);
          }
          const concat = tf.layers.concatenate({ axis: -1 }).apply(headOutputs);
          const output = tf.layers.dense({ units: tokenDim, useBias: false }).apply(concat);
          const dropped = tf.layers.dropout({ rate: dropoutRate }).apply(output);
          const added = tf.layers.add().apply([inputTensor, dropped]);
          const norm = tf.layers.layerNormalization().apply(added);
          return norm;
        }
        // Build dueling DQN with stacked self-attention layers.
        buildDuelingDQN() {
          // Input dimension is 512 from the USE embedding.
          const input = tf.input({ shape: [512] });
          let x = tf.layers.dense({ units: 512, activation: 'relu' }).apply(input);
          // Reshape into a sequence for attention: 8 tokens × 64 dims = 512.
          let reshaped = tf.layers.reshape({ targetShape: [8, 64] }).apply(x);
          let attnOut1 = this.multiHeadSelfAttention(reshaped, 4, 0.1);
          let attnOut2 = this.multiHeadSelfAttention(attnOut1, 4, 0.1);
          let flattened = tf.layers.flatten().apply(attnOut2);
          const valueStream = tf.layers.dense({ units: 64, activation: 'relu' }).apply(flattened);
          const value = tf.layers.dense({ units: 1, activation: 'linear' }).apply(valueStream);
          const advantageStream = tf.layers.dense({ units: 64, activation: 'relu' }).apply(flattened);
          const advantage = tf.layers.dense({ units: responses.length, activation: 'linear' }).apply(advantageStream);
          const meanAdvantageLayer = new LambdaLayer(a => tf.sub(a, tf.mean(a, 1, true)), null);
          const meanAdvantage = meanAdvantageLayer.apply(advantage);
          const qValues = tf.layers.add().apply([value, meanAdvantage]);
          const model = tf.model({ inputs: input, outputs: qValues });
          model.compile({ optimizer: tf.train.adam(this.learningRate), loss: 'meanSquaredError' });
          return model;
        }
        // Enhanced feature extraction using Universal Sentence Encoder.
        async extractFeatures(message) {
          let combinedMessage = message;
          return new Promise(async (resolve) => {
            if (useModel) {
              try {
                const embedding = await useModel.embed(combinedMessage);
                const embArray = await embedding.array();
                // Store embedding for context retrieval.
                memoryModule.addMemory(embArray[0], combinedMessage);
                embedding.dispose();
                resolve(embArray[0]);
              } catch (err) {
                console.error("Error in USE embedding:", err);
                const fallback = Array(512).fill(0);
                fallback[0] = combinedMessage.length / 100;
                resolve(fallback);
              }
            } else {
              const fallback = Array(512).fill(0);
              fallback[0] = combinedMessage.length / 100;
              resolve(fallback);
            }
          });
        }
        decideAction(features) {
          let action;
          if (Math.random() < this.epsilon) {
            action = Math.floor(Math.random() * responses.length);
          } else {
            action = tf.tidy(() => {
              const stT = tf.tensor2d([features]);
              const out = this.model.predict(stT);
              const arr = out.dataSync();
              return argmax(arr);
            });
          }
          return action;
        }
        // Process a message: extract features, decide action, store experience.
        async step(message) {
          const features = await this.extractFeatures(message);
          const action = this.decideAction(features);
          const reward = calculateReward(message, action);
          const experience = { state: features, action: action, reward: reward, nextState: features, done: false };
          this.exp.push(experience);
          this.priorityBuffer.add(experience);
          if (this.priorityBuffer.size() > 64) await this.learn();
          if (this.epsilon > 0.05) this.epsilon *= this.epsilonDecay;
          this.stepCount++;
          updateStepDisplay(this.stepCount);
          return { action, features };
        }
        // Learn using Double DQN update with prioritized experience replay.
        async learn() {
          const batchSize = 64;
          const batch = this.priorityBuffer.sample(batchSize);
          const states = batch.map(e => e.state);
          const actions = batch.map(e => e.action);
          const rewards = batch.map(e => e.reward);
          const nextStates = batch.map(e => e.nextState);
          const sT = tf.tensor2d(states);
          const nsT = tf.tensor2d(nextStates);
          const currQ = this.model.predict(sT);
          const nextTargetQ = this.targetModel.predict(nsT);
          const nextMainQ = this.model.predict(nsT);
          const currData = currQ.arraySync();
          const nextTargetData = nextTargetQ.arraySync();
          const nextMainData = nextMainQ.arraySync();
          for (let i = 0; i < batch.length; i++) {
            const doubleAction = argmax(nextMainData[i]);
            currData[i][actions[i]] = rewards[i] + 0.99 * nextTargetData[i][doubleAction];
          }
          const target = tf.tensor2d(currData);
          try {
            const info = await this.model.fit(sT, target, { epochs: 1, verbose: 0 });
            const loss = info.history.loss[0];
            this.lossHistory.push(loss);
            this.lossData.push(loss);
            this.lossVarianceWindow.push(loss);
            if (this.lossVarianceWindow.length > 5) this.lossVarianceWindow.shift();
            const meanLoss = this.lossVarianceWindow.reduce((a, b) => a + b, 0) / this.lossVarianceWindow.length;
            const variance = this.lossVarianceWindow.reduce((sum, l) => sum + Math.pow(l - meanLoss, 2), 0) / this.lossVarianceWindow.length;
            if (variance > 0.01) {
              this.learningRate *= 0.98;
            } else {
              this.learningRate *= 1.01;
            }
            this.model.optimizer.learningRate = this.learningRate;
            lossDisplay.textContent = "Loss: " + loss.toFixed(4);
            updateLossChart(this.lossData);
            if (this.stepCount % 100 === 0) {
              const tau = 0.1;
              const weights = this.model.getWeights();
              const targetWeights = this.targetModel.getWeights();
              const updated = weights.map((w, i) => tf.add(tf.mul(w, tau), tf.mul(targetWeights[i], 1 - tau)));
              this.targetModel.setWeights(updated);
              updated.forEach(t => t.dispose());
            }
          } catch (err) {
            console.error("Learning error:", err);
          } finally {
            tf.dispose([sT, nsT, currQ, nextTargetQ, nextMainQ, target]);
          }
        }
        trainExtra() {
          for (let i = 0; i < 100; i++) {
            this.step("dummy");
          }
          logEvent("Commander trained extra for 100 steps.");
        }
      }

      // Instantiate CommanderAgent.
      const commander = new CommanderAgent();

      // Export model functionality.
      async function exportModel() {
        try {
          await commander.model.save('downloads://chatbot-model');
          logEvent("Model exported successfully.");
        } catch (e) {
          console.error("Export error:", e);
          logEvent("Failed to export model.");
        }
      }

      // Import model from file.
      document.getElementById("modelUpload").addEventListener("change", async (evt) => {
        const files = evt.target.files;
        if (files.length === 0) return;
        try {
          const loadedModel = await tf.loadLayersModel(tf.io.browserFiles(files));
          commander.model = loadedModel;
          commander.targetModel = loadedModel;
          logEvent("Model imported successfully.");
        } catch (e) {
          console.error("Import error:", e);
          logEvent("Failed to import model.");
        }
      });

      // Reset model and clear backups.
      window.resetModel = function() {
        if (confirm("This will reset the model and clear backup data. Continue?")) {
          localStorage.removeItem("backup-model");
          localStorage.removeItem("performanceMetrics");
          location.reload();
        }
      };

      // Deep Seek functionality using advanced memory retrieval.
      async function deepSeek() {
        const query = prompt("Enter your deep seek query:");
        if (!query) return;
        const result = await memoryModule.searchMemory(query);
        appendMessage("DeepSeek", result ? "Most similar context: " + result : "No similar context found.");
      }

      // Save chat history to a text file.
      function saveChat() {
        const chatText = conversationHistory.join("\n");
        const blob = new Blob([chatText], { type: "text/plain" });
        const link = document.createElement("a");
        link.href = URL.createObjectURL(blob);
        link.download = "chat_history.txt";
        link.click();
      }

      // Show the last 10 memory texts.
      function showMemory() {
        if (memoryModule.memories.length === 0) {
          alert("No memory stored yet.");
        } else {
          const recentMemory = memoryModule.memories.slice(-10).map(m => m.text).join("\n");
          alert("Recent Memory:\n" + recentMemory);
        }
      }

      // Handle incoming user message.
      async function handleMessage() {
        const message = userInput.value.trim();
        if (!message) return;
        appendMessage("User", message);
        conversationHistory.push("User: " + message);
        userInput.value = "";
        // Use the last 3 messages as context.
        const contextMessage = conversationHistory.slice(-3).join(" ");
        try {
          const result = await commander.step(contextMessage);
          const action = result.action;
          const features = result.features;
          const response = await getResponse(action);
          appendMessage("Chatbot", response, features);
          conversationHistory.push("Chatbot: " + response);
        } catch (error) {
          console.error("Error processing message:", error);
          appendMessage("Chatbot", "Sorry, I encountered an error and could not respond.");
          logEvent("Error during message processing: " + error.message);
        } finally {
          updatePerformancePanel();
        }
      }

      sendButton.addEventListener("click", handleMessage);
      userInput.addEventListener("keydown", (e) => {
        if (e.key === "Enter") handleMessage();
      });

      // Pre-training routine with sample messages.
      async function preTrainChatbot() {
        const inputs = [];
        const labels = [];
        for (let i = 0; i < 500; i++) {
          const text = "sample message " + i;
          const features = await commander.extractFeatures(text);
          const action = Math.floor(Math.random() * responses.length);
          const labelVec = Array(responses.length).fill(0);
          labelVec[action] = 1;
          inputs.push(features);
          labels.push(labelVec);
        }
        const xs = tf.tensor2d(inputs);
        const ys = tf.tensor2d(labels);
        try {
          await commander.model.fit(xs, ys, { epochs: 40 });
          logEvent("Pre-training complete.");
        } catch (err) {
          console.error("Pre-training error:", err);
          logEvent("Pre-training encountered an error.");
        } finally {
          xs.dispose();
          ys.dispose();
        }
      }
      preTrainChatbot();

      // Background training and performance updates.
      setInterval(() => {
        commander.trainExtra();
        updatePerformancePanel();
      }, 30000);

      setInterval(async () => {
        const quote = await fetchQuote();
        if (quote && !quote.startsWith("Error")) {
          commander.step(quote);
          logEvent("Background training with quote: " + quote.slice(0, 50) + "...");
        }
        const catFact = await fetchCatFact();
        if (catFact && !catFact.startsWith("Error")) {
          commander.step(catFact);
          logEvent("Background training with cat fact: " + catFact.slice(0, 50) + "...");
        }
        const chuck = await fetchChuckNorris();
        if (chuck && !chuck.startsWith("Error")) {
          commander.step(chuck);
          logEvent("Background training with Chuck Norris: " + chuck.slice(0, 50) + "...");
        }
        const kanye = await fetchKanye();
        if (kanye && !kanye.startsWith("Error")) {
          commander.step(kanye);
          logEvent("Background training with Kanye: " + kanye.slice(0, 50) + "...");
        }
      }, 20000);

      updatePerformancePanel();

      // Auto-backup model and performance metrics every 60 seconds.
      setInterval(async () => {
        try {
          await commander.model.save('localstorage://backup-model');
          const metrics = {
            stepCount: commander.stepCount,
            epsilon: commander.epsilon,
            lossData: commander.lossData.slice(-20)
          };
          localStorage.setItem("performanceMetrics", JSON.stringify(metrics));
          logEvent("Model and metrics auto-backup saved to localStorage.");
        } catch (e) {
          console.error("Auto-backup error:", e);
        }
      }, 60000);

      (async function loadBackup() {
        try {
          const backupModel = await tf.loadLayersModel('localstorage://backup-model');
          commander.model = backupModel;
          commander.targetModel = backupModel;
          const metrics = localStorage.getItem("performanceMetrics");
          if (metrics) {
            const parsed = JSON.parse(metrics);
            logEvent("Backup metrics loaded: " + JSON.stringify(parsed));
          }
          logEvent("Backup model loaded from localStorage.");
        } catch (e) {
          console.log("No backup model found, starting fresh.");
        }
      })();

      // Dynamically update the DALL·E image using an AI art query from Unsplash.
      function updateDalleImage() {
        const dalleImg = document.getElementById("dalleImage");
        dalleImg.src = "https://source.unsplash.com/320x200/?ai,art&" + Date.now();
      }
      setInterval(updateDalleImage, 60000);
      updateDalleImage();

      updatePerformancePanel();
    })();
  </script>
</body>
</html>
